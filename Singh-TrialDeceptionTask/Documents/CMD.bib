@misc{CRFsuite,
	author = {Naoaki Okazaki},
	title = {CRFsuite: a fast implementation of Conditional Random Fields (CRFs)},
	url = {http://www.chokkan.org/software/crfsuite/},
	year = {2007}
}
@inproceedings{fengLinearTimeBottomUpDiscourse2014,
  title = {A {{Linear}}-{{Time Bottom}}-{{Up Discourse Parser}} with {{Constraints}} and {{Post}}-{{Editing}}},
  booktitle = {Proceedings of the 52nd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Feng, Vanessa Wei and Hirst, Graeme},
  year = {2014},
  month = jun,
  pages = {511--521},
  publisher = {{Association for Computational Linguistics}},
  address = {{Baltimore, Maryland}},
  doi = {10.3115/v1/P14-1048},
  file = {/home/rav/CitationResources/Zotero/storage/2PIE9YGY/Feng and Hirst - 2014 - A Linear-Time Bottom-Up Discourse Parser with Cons.pdf}
}

@article{fengTwopassDiscourseSegmentation2014,
  title = {Two-Pass {{Discourse Segmentation}} with {{Pairing}} and {{Global Features}}},
  author = {Feng, Vanessa Wei and Hirst, Graeme},
  year = {2014},
  month = jul,
  abstract = {Previous attempts at RST-style discourse segmentation typically adopt features centered on a single token to predict whether to insert a boundary before that token. In contrast, we develop a discourse segmenter utilizing a set of pairing features, which are centered on a pair of adjacent tokens in the sentence, by equally taking into account the information from both tokens. Moreover, we propose a novel set of global features, which encode characteristics of the segmentation as a whole, once we have an initial segmentation. We show that both the pairing and global features are useful on their own, and their combination achieved an \$F\_1\$ of 92.6\% of identifying in-sentence discourse boundaries, which is a 17.8\% error-rate reduction over the state-of-the-art performance, approaching 95\% of human performance. In addition, similar improvement is observed across different classification frameworks.},
  archivePrefix = {arXiv},
  eprint = {1407.8215},
  eprinttype = {arxiv},
  file = {/home/rav/CitationResources/Zotero/storage/VXFKQ2AQ/Feng and Hirst - 2014 - Two-pass Discourse Segmentation with Pairing and G.pdf;/home/rav/CitationResources/Zotero/storage/AL9CT4HB/1407.html},
  journal = {arXiv:1407.8215 [cs]},
  keywords = {Computer Science - Computation and Language},
  primaryClass = {cs}
}

@article{iaconoAccuracyPolygraphTechniques2008,
  title = {Accuracy of Polygraph Techniques: {{Problems}} Using Confessions to Determine Ground Truth},
  author = {Iacono, William G.},
  year = {2008},
  volume = {95},
  pages = {24--26},
  issn = {0031-9384},
  doi = {10.1016/j.physbeh.2008.06.001},
  abstract = {Mangan et al. [D.J. Mangan, T.E., Armitage, G.C., Adams: A field study on the validity of the Quadri-Track Zone Comparison Technique. Physiol Behav 2008] have carried out a field study of polygraph test accuracy in which they relied on confessions to determine guilt as well as to clear co-suspects in the same case as innocent. Using this criterion for ground truth, they estimate polygraph accuracy by determining how often confessions are matched by failed polygraph tests and how often those cleared by confession have passed polygraph tests. They conclude that the polygraph was ``100\% accurate in the identification of the innocent and guilty.'' However, their method contains a flaw, not discernible by reading their article, that invalidates this conclusion. The flaw arises because confessions were obtained by the polygraph examiner who interrogated the examinee after deciding the test was failed. Under these circumstances, the criterion (the confession) and the test outcome (deception indicated) are not independent. The method thus virtually guarantees that the two will match, ensuring 100\% ``accuracy.'' Although largely ignored by the polygraph profession, this flaw inherent to confession-based field studies of polygraph validity has been known to confound these studies for over two decades. Hence, contrary to Mangan et al., their study design does not provide for an adequate estimate of polygraph test accuracy. Moreover, reviews of polygraph testing carried out by scientists at arms length to the polygraph profession have repeatedly failed to support the accuracy proponents claim for the polygraph.},
  journal = {Physiology \& Behavior},
  keywords = {Accuracy,Control question polygraph test,Establishing ground truth with confessions,Reliability,Validity},
  number = {1}
}

@article{linPDTBstyledEndtoendDiscourse2014,
  title = {A {{PDTB}}-Styled End-to-End Discourse Parser},
  author = {Lin, Ziheng and Ng, Hwee Tou and Kan, Min-Yen},
  year = {2014},
  month = apr,
  volume = {20},
  pages = {151--184},
  publisher = {{Cambridge University Press}},
  issn = {1351-3249, 1469-8110},
  doi = {10.1017/S1351324912000307},
  abstract = {Since the release of the large discourse-level annotation of the Penn Discourse Treebank (PDTB), research work has been carried out on certain subtasks of this annotation, such as disambiguating discourse connectives and classifying Explicit or Implicit relations. We see a need to construct a full parser on top of these subtasks and propose a way to evaluate the parser. In this work, we have designed and developed an end-to-end discourse parser-to-parse free texts in the PDTB style in a fully data-driven approach. The parser consists of multiple components joined in a sequential pipeline architecture, which includes a connective classifier, argument labeler, explicit classifier, non-explicit classifier, and attribution span labeler. Our trained parser first identifies all discourse and non-discourse relations, locates and labels their arguments, and then classifies the sense of the relation between each pair of arguments. For the identified relations, the parser also determines the attribution spans, if any, associated with them. We introduce novel approaches to locate and label arguments, and to identify attribution spans. We also significantly improve on the current state-of-the-art connective classifier. We propose and present a comprehensive evaluation from both component-wise and error-cascading perspectives, in which we illustrate how each component performs in isolation, as well as how the pipeline performs with errors propagated forward. The parser gives an overall system F1 score of 46.80 percent for partial matching utilizing gold standard parses, and 38.18 percent with full automation.},
  file = {/home/rav/CitationResources/Zotero/storage/SDL7F9FB/Lin et al. - 2014 - A PDTB-styled end-to-end discourse parser.pdf;/home/rav/CitationResources/Zotero/storage/VIVKI3XF/9F090341941A9D1965FF6AFB59378B23.html},
  journal = {Natural Language Engineering},
  language = {en},
  number = {2}
}

@inproceedings{perez-rosasDeceptionDetectionUsing2015,
  title = {Deception {{Detection}} Using {{Real}}-Life {{Trial Data}}},
  booktitle = {Proceedings of the 2015 {{ACM}} on {{International Conference}} on {{Multimodal Interaction}}},
  author = {{P{\'e}rez-Rosas}, Ver{\'o}nica and Abouelenien, Mohamed and Mihalcea, Rada and Burzo, Mihai},
  year = {2015},
  month = nov,
  pages = {59--66},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2818346.2820758},
  abstract = {Hearings of witnesses and defendants play a crucial role when reaching court trial decisions. Given the high-stake nature of trial outcomes, implementing accurate and effective computational methods to evaluate the honesty of court testimonies can offer valuable support during the decision making process. In this paper, we address the identification of deception in real-life trial data. We introduce a novel dataset consisting of videos collected from public court trials. We explore the use of verbal and non-verbal modalities to build a multimodal deception detection system that aims to discriminate between truthful and deceptive statements provided by defendants and witnesses. We achieve classification accuracies in the range of 60-75\% when using a model that extracts and fuses features from the linguistic and gesture modalities. In addition, we present a human deception detection study where we evaluate the human capability of detecting deception in trial hearings. The results show that our system outperforms the human capability of identifying deceit.},
  isbn = {978-1-4503-3912-4},
  keywords = {deception detection,multimodal,non-verbal,real-life trial,verbal},
  series = {{{ICMI}} '15}
}


